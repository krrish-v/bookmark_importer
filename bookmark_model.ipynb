{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
    {
      "cell_type": "code",
      "source": [
        "!pip install sklearn"
      ],
      "metadata": {
        "id": "N8yhl-tG26TM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pickle\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "aWXCFZ8w38ZW"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import numpy as np\n",
        "\n",
        "module_url = \"https://tfhub.dev/google/universal-sentence-encoder/4\" \n",
        "model = hub.load(module_url)\n",
        "print (\"module %s loaded\" % module_url)"
      ],
      "metadata": {
        "id": "emt2bIVC2dJx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('/content/drive/MyDrive/medium_articles_drop.csv')\n",
        "data.drop(['authors', 'timestamp'], inplace=True, axis=1)\n",
        "\n",
        "data.head"
      ],
      "metadata": {
        "id": "R3UnfXvo-wBi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tags = data['tags']\n",
        "title = data['text']\n",
        "heading = data['title']"
      ],
      "metadata": {
        "id": "Dyl2up9H-5vj"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_tags = np.array(tags)\n",
        "all_tags.shape"
      ],
      "metadata": {
        "id": "1XsFMO6QoyPe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "460e7c31-66ff-431c-cef6-54cbc4dac404"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1600,)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')"
      ],
      "metadata": {
        "id": "uCFUDbY8FGJa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize, RegexpTokenizer\n",
        "from nltk import SnowballStemmer, WordNetLemmatizer, pos_tag\n",
        "from nltk.corpus import stopwords\n",
        "from string import punctuation\n",
        "import re\n",
        "from pprint import pprint"
      ],
      "metadata": {
        "id": "3-R_V1awO82e"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stop_words = stopwords.words('english')"
      ],
      "metadata": {
        "id": "tMx51FGsY8oG"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cleaned_tokens = []\n",
        "\n",
        "# textcleaning\n",
        "def long_text_cleaning(text: list):\n",
        "     \n",
        "    for sen in text:\n",
        "        sentence_tokenize = sent_tokenize(sen)\n",
        "\n",
        "        cleaned_sen = []\n",
        "        for sent_token in sentence_tokenize:\n",
        "            \n",
        "            new_sen = []\n",
        "\n",
        "            words_tokenize = word_tokenize(sent_token)\n",
        "            prasser_tags = pos_tag(words_tokenize)\n",
        "            \n",
        "            for token, tag in prasser_tags:\n",
        "                token = re.sub(\"[!$%&'()*+,-./:;<=>?@[\\]^_`{|} ~0-9]\",\"\", token)\n",
        "\n",
        "                if len(token) != 1:\n",
        "\n",
        "                    if tag.startswith(\"NN\"):\n",
        "                        pos = 'n'\n",
        "                    elif tag.startswith('VB'):\n",
        "                        pos = 'v'\n",
        "                    else:\n",
        "                        pos = 'a'\n",
        "\n",
        "                    lemmatizer = WordNetLemmatizer()\n",
        "                    token = lemmatizer.lemmatize(token, pos)\n",
        "            \n",
        "                    filtered_word = token.lower()\n",
        "\n",
        "                    if len(token) > 0 and filtered_word not in stop_words:\n",
        "                        new_sen.append(filtered_word)\n",
        "\n",
        "            cleaned_sen.append([' '.join(new_sen)])\n",
        "\n",
        "        cleaned_tokens.append(cleaned_sen)\n",
        "\n",
        "long_text_cleaning(title)\n"
      ],
      "metadata": {
        "id": "rJXogbXgNJ6L"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f_text_clean = open('text_cleaning.sav', 'wb')\n",
        "pickle.dump(long_text_cleaning, f_text_clean)\n",
        "f_text_clean.close()"
      ],
      "metadata": {
        "id": "f7OkHr18fgjT"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cleaned_tokens[0]"
      ],
      "metadata": {
        "id": "6iaizT4_PiPE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cleaned_text = [' '.join(sent_[0] for sent_ in sent) for sent in cleaned_tokens]"
      ],
      "metadata": {
        "id": "nerVNI642YAq"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cleaned_text[0]"
      ],
      "metadata": {
        "id": "l7MPuj7PQZvt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "use_title = model(cleaned_text).numpy()\n",
        "\n",
        "use_title.shape\n",
        "use_title.dtype"
      ],
      "metadata": {
        "id": "xELSJUTu2jpV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "86f2bc76-0b9a-4aca-fc95-85febc152f2d"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dtype('float32')"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "use_title[0]"
      ],
      "metadata": {
        "id": "y117aGZbRIXW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7a62ea75-46b5-4719-cac4-7b2970d3daed"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dtype('float32')"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Reforming heading"
      ],
      "metadata": {
        "id": "V0HcVk5wRa4S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def heading_cleaning(title: np.array):\n",
        "    \n",
        "    all_cleaned_title = []\n",
        "    stemmer = SnowballStemmer('english')\n",
        "\n",
        "    for tit in title:\n",
        "        cleaned_title = []\n",
        "        all_tit_words = word_tokenize(tit)\n",
        "\n",
        "        for word in all_tit_words:\n",
        "\n",
        "            word = re.sub('[0-9]', '', word)\n",
        "            word = stemmer.stem(word)\n",
        "        \n",
        "            if word not in stop_words and word not in punctuation and len(word) > 1:\n",
        "\n",
        "                cleaned_title.append(word)\n",
        "        \n",
        "        all_cleaned_title.append(' '.join(cleaned_title))\n",
        "    \n",
        "    return all_cleaned_title\n",
        "\n",
        "all_cleaned_title = heading_cleaning(heading)"
      ],
      "metadata": {
        "id": "UGvnJTdZEeov"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f_heading_clean = open('heading_cleaning.sav', 'wb')\n",
        "pickle.dump(heading_cleaning, f_heading_clean)\n",
        "f_heading_clean.close()"
      ],
      "metadata": {
        "id": "yBdp1SwKg3tz"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_cleaned_title[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "brOPxBSPExri",
        "outputId": "8d4b3db1-5140-407b-fa34-5399e55418d0"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'mental note vol'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cleaned_tit = np.array(all_cleaned_title)\n",
        "\n",
        "cleaned_tit.shape"
      ],
      "metadata": {
        "id": "GETp4jC6zMlq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "use_title.astype('double')\n",
        "use_title.dtype"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CoMasKgW2M5G",
        "outputId": "fc735899-29f3-4170-f381-476acc6bb68a"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dtype('float32')"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.cluster import KMeans"
      ],
      "metadata": {
        "id": "x8L9h-JpE2tW"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "no_of_clusters = 400\n",
        "means = KMeans(n_clusters=no_of_clusters)\n",
        "means.fit(use_title)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ehkcbrJexRDD",
        "outputId": "0ec04b7f-176d-4782-d999-c41a5b4450fb"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "KMeans(n_clusters=400)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "f_model = open('prid_model.sav', 'wb')\n",
        "pickle.dump(means, f_model)\n",
        "f_model.close()"
      ],
      "metadata": {
        "id": "OqIlfVaecG0h"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_km = means.fit_predict(use_title)"
      ],
      "metadata": {
        "id": "JhBqggSKy0l4"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "y = cleaned_tit\n",
        "\n",
        "for i in range(no_of_clusters):\n",
        "    y_plot = use_title[y_km==i, 0]\n",
        "    x_plot = np.array([y[np.where(use_title == ind)[0][0]] for ind in y_plot]).reshape(-1)\n",
        "\n",
        "    plt.scatter(x_plot, y_plot, s=5)\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "apUdhYEUYiFL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "set_tags = {}\n",
        "\n",
        "for i in range(no_of_clusters):\n",
        "    \n",
        "    k1 = use_title[y_km==i, :512]\n",
        "    topic = np.array([all_tags[np.where(use_title == ind)[0][0]] for ind in k1]).reshape(-1)\n",
        "\n",
        "    noth_topic = []\n",
        "    for w in topic:\n",
        "      \n",
        "      seno_topic = word_tokenize(re.sub(\"[!$%&'()*+,-./:;<=>?@[\\]^_`{|}~0-9]\", '', w))\n",
        "      \n",
        "      ray_topic = [topc for topc in seno_topic if len(topc) > 2]\n",
        "      noth_topic.append(ray_topic)\n",
        "\n",
        "    set_tags['topic ' + str(i)] = noth_topic\n"
      ],
      "metadata": {
        "id": "XbYAJQmvVBzO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "set_tags['topic 3']"
      ],
      "metadata": {
        "id": "o4hyIWOyq_I8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "f_prid_tags = open('pridicted_tags.json', 'w')\n",
        "json.dump(set_tags, f_prid_tags)\n",
        "f_prid_tags.close()"
      ],
      "metadata": {
        "id": "J9tiA9fRTpzb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
